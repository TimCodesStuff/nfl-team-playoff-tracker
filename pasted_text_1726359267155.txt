Objective:
Create a web application that tracks and visualizes NFL playoff probabilities for all teams throughout the season.

Key Components:

Backend (Python):

Flask web application (main.py)
PostgreSQL database (database.py)
Web scraper (scraper.py)
Database regeneration script (db_regenerate.py)
Frontend:

HTML template (templates/index.html)
CSS styles (static/css/styles.css)
JavaScript for data visualization (static/js/app.js)
External Libraries:

Flask
psycopg2 (for PostgreSQL)
requests and BeautifulSoup (for web scraping)
APScheduler (for scheduling scraper)
Chart.js (for data visualization)
Functionality:

Scraper (scraper.py):

Fetches data from https://www.playoffstatus.com/nfl/nflpostseasonprob.html
Parses HTML to extract playoff probabilities for each team
Runs every 2 hours using APScheduler
Database (database.py):

Stores playoff probabilities for each team
Provides functions to initialize DB, insert data, and retrieve data
Web Application (main.py):

Serves the frontend
Provides API endpoints for fetching probability data
Initializes and schedules the scraper
Frontend (index.html, styles.css, app.js):

Displays five charts: Round 1, Round 2, Conference Championship, Super Bowl Appearance, Super Bowl Winner
Uses Chart.js for interactive, responsive charts
Implements a global legend for all charts
Shows last updated timestamp
Key Features:

Real-time data updates every 2 hours
Interactive charts with hover-over tooltips
Responsive design for various screen sizes
Color-coded teams in charts and legend
Implementation Steps:

Set up Flask application with necessary routes
Implement database functions for data storage and retrieval
Create web scraper to fetch and parse NFL playoff probabilities
Design and implement frontend with Chart.js for data visualization
Set up scheduled scraping using APScheduler
Implement API endpoints for fetching probability data
Add features like global legend, hover-over tooltips, and last updated timestamp
To recreate this project:

Set up a new repl with Python and Flask
Install required libraries (Flask, psycopg2, requests, beautifulsoup4, apscheduler)
Create the main Python files (main.py, database.py, scraper.py, db_regenerate.py)
Set up the frontend structure (templates and static folders)
Implement the backend logic for scraping, data storage, and API endpoints
Create the frontend HTML, CSS, and JavaScript files
Test and debug the application
Note: Ensure that the necessary environment variables (PGHOST, PGUSER, PGDATABASE, PGPASSWORD, PGPORT) are set for database connection.